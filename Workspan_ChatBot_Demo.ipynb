{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Workspan ChatBot Demo - OpenAI , LangChain and Astra Vector Search"
      ],
      "metadata": {
        "id": "kA3U25-l-ho_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WorkSpan is an Ecosystem Management platform. It is used to efficiently manage co-sell opportunities with partners, scaling the co-sell pipeline, revenue, and wins.\n",
        "\n",
        "The WorkSpan team wants to integrate GenAI features, such as chatbot, into their applications by leveraging Astra Vector Search and LLM Models."
      ],
      "metadata": {
        "id": "-rXqlr8JnP0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "Iim0shMFhid0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cassio ragstack-ai openai tiktoken gradio"
      ],
      "metadata": {
        "id": "IoOIHxGvNg2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from getpass import getpass\n",
        "\n",
        "import cassio\n",
        "\n",
        "from langchain.vectorstores import Cassandra\n",
        "from langchain.schema import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "FihDLEKkUZwJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keys & Environment Variables"
      ],
      "metadata": {
        "id": "lw97aF-znrTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_ID = \"\"\n",
        "ASTRA_DB_APPLICATION_TOKEN = \"\"\n",
        "ASTRA_DB_KEYSPACE = \"workspan\""
      ],
      "metadata": {
        "id": "MY1ioLbuOFIS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cassio.init(\n",
        "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
        "    database_id=ASTRA_DB_ID,\n",
        "    keyspace=ASTRA_DB_KEYSPACE if ASTRA_DB_KEYSPACE else None,\n",
        ")"
      ],
      "metadata": {
        "id": "WE2nS5F-PuUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set up OpenAI Objects and Vector Store"
      ],
      "metadata": {
        "id": "gMQlKn02KPDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"\"\n",
        "llm_openai = OpenAI(temperature=0)\n",
        "openai_embeddings = OpenAIEmbeddings()\n",
        "\n",
        "vector_store = Cassandra(\n",
        "    embedding=openai_embeddings,\n",
        "    table_name=\"customer_opportunities_openai\",\n",
        "    session=None,  # <-- meaning: use the global defaults from cassio.init()\n",
        "    keyspace=None,  # <-- meaning: use the global defaults from cassio.init()\n",
        ")\n"
      ],
      "metadata": {
        "id": "Psq9_c8tKVq1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Populate Vector Store"
      ],
      "metadata": {
        "id": "lZCU72O5IDFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_documents = []\n",
        "\n",
        "# record #1\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "From Michael, confirmed deprioritize. From Anjaney, account executive interest to schedule meeting - Anjaney to schedule call with Nirav/Amy on R&D.\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "Next Step:\n",
        "08/16/2023 : Review partner information updates and update opportunity details. 8/17(LR) - connecting with Partner to offer co-sell support\n",
        "\n",
        "Next Step History:\n",
        "null;08/16/2023 : Review partner information updates and update opportunity details.;08/16/2023 : Review partner information updates and update opportunity details. 8/17(LR) - connecting with Partner to offer co-sell support\n",
        "\"\"\"\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS100', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-7202838a', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "input_document = Document(page_content=next_step_and_cadence, metadata=metadata)\n",
        "input_documents.append(input_document)\n",
        "print(input_document)\n",
        "\n",
        "\n",
        "# record #2\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "From Autumn, send recording of last call and our discussed inputs from demo 8/28. Ramesh will provide to Caroline by early next week (of 9/11).\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "REVIEW TECH & Economic Proposal\n",
        "\"\"\"\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS100', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-8a038b8a', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "input_document = Document(page_content=next_step_and_cadence, metadata=metadata)\n",
        "input_documents.append(input_document)\n",
        "print(input_document)\n",
        "\n",
        "\n",
        "# record #3\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "Joint sync set for 9/7. Enablement session to follow + in person account mapping. Caroline / Michael to begin coordinating. EAI presence\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "07/05/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support\n",
        "\"\"\"\n",
        "\n",
        "next_step_and_cadence = next_step + cadence\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS100', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-8a3b0348', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "input_document = Document(page_content=next_step_and_cadence, metadata=metadata)\n",
        "input_documents.append(input_document)\n",
        "print(input_document)\n",
        "\n",
        "\n",
        "# record #4\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Action Items:\n",
        "From Caroline, user community engaged to respond to questions. @Dataiku - How can we get initial data from user community/pull together PoV for client? Action (Asan/Ken (sp?)): In-person outreach to Deloitte users and follow-up to 5 responses received.\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "null;06/20/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support;07/05/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support\n",
        "\"\"\"\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS100', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-8a7128a3', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "input_document = Document(page_content=next_step_and_cadence, metadata=metadata)\n",
        "input_documents.append(input_document)\n",
        "print(input_document)\n",
        "\n",
        "\n",
        "# record #5\n",
        "\n",
        "next_step = f\"\"\"\n",
        "Propsal did not go thru. No budget Left. Negative.\n",
        "\"\"\"\n",
        "\n",
        "cadence = f\"\"\"\n",
        "No further follow up required.\n",
        "\"\"\"\n",
        "\n",
        "metadata = {\"customer_id\": 'CUS100', \"partner_id\": 'AWS', \"opportunity_id\": 'WS-8a7128a4', \"customer_name\": 'Teradyne, Inc.' }\n",
        "next_step_and_cadence = \"{} : {} : {}\".format(metadata, next_step, cadence)\n",
        "input_document = Document(page_content=next_step_and_cadence, metadata=metadata)\n",
        "input_documents.append(input_document)\n",
        "print(input_document)\n",
        "\n",
        "print(f\"Adding {len(input_documents)} documents ... \", end=\"\")\n",
        "vector_store.add_documents(documents=input_documents, batch_size=50)\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcXmEP4M2Z9K",
        "outputId": "0c59cc3c-5a86-4012-f236-b8bc196644b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content=\"{'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-7202838a', 'customer_name': 'Teradyne, Inc.'} : \\nAction Items:\\nFrom Michael, confirmed deprioritize. From Anjaney, account executive interest to schedule meeting - Anjaney to schedule call with Nirav/Amy on R&D.\\n : \\nNext Step:\\n08/16/2023 : Review partner information updates and update opportunity details. 8/17(LR) - connecting with Partner to offer co-sell support\\n\\nNext Step History:\\nnull;08/16/2023 : Review partner information updates and update opportunity details.;08/16/2023 : Review partner information updates and update opportunity details. 8/17(LR) - connecting with Partner to offer co-sell support\\n\" metadata={'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-7202838a', 'customer_name': 'Teradyne, Inc.'}\n",
            "page_content=\"{'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-8a038b8a', 'customer_name': 'Teradyne, Inc.'} : \\nAction Items:\\nFrom Autumn, send recording of last call and our discussed inputs from demo 8/28. Ramesh will provide to Caroline by early next week (of 9/11).\\n : \\nREVIEW TECH & Economic Proposal\\n\" metadata={'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-8a038b8a', 'customer_name': 'Teradyne, Inc.'}\n",
            "page_content=\"{'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-8a3b0348', 'customer_name': 'Teradyne, Inc.'} : \\nAction Items:\\nJoint sync set for 9/7. Enablement session to follow + in person account mapping. Caroline / Michael to begin coordinating. EAI presence\\n : \\n07/05/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support\\n\" metadata={'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-8a3b0348', 'customer_name': 'Teradyne, Inc.'}\n",
            "page_content=\"{'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-8a7128a3', 'customer_name': 'Teradyne, Inc.'} : \\nAction Items:\\nFrom Caroline, user community engaged to respond to questions. @Dataiku - How can we get initial data from user community/pull together PoV for client? Action (Asan/Ken (sp?)): In-person outreach to Deloitte users and follow-up to 5 responses received.\\n : \\nnull;06/20/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support;07/05/2023: Contact Federico Gandolfo,federico.hernan.gandolfo@abc.com,+54.911.3204.4871 to discuss Deal support\\n\" metadata={'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-8a7128a3', 'customer_name': 'Teradyne, Inc.'}\n",
            "page_content=\"{'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-8a7128a4', 'customer_name': 'Teradyne, Inc.'} : \\nPropsal did not go thru. No budget Left. Negative.\\n : \\nNo further follow up required.\\n\" metadata={'customer_id': 'CUS100', 'partner_id': 'AWS', 'opportunity_id': 'WS-8a7128a4', 'customer_name': 'Teradyne, Inc.'}\n",
            "Adding 5 documents ... Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set up prompt template"
      ],
      "metadata": {
        "id": "TUxTOqf2pE3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_str = \"\"\"Human: Use the following pieces of context to provide a concise answer to the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Assistant:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(prompt_template_str)"
      ],
      "metadata": {
        "id": "sMNRwVqo-sdC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Answer Questions - OpenAI"
      ],
      "metadata": {
        "id": "cUL3djRTOhha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "model_id = \"gpt-4\"\n",
        "\n",
        "req_accept = \"application/json\"\n",
        "req_content_type = \"application/json\"\n",
        "\n",
        "# This, created from the vector store, will fetch the top relevant documents given a text query\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "def answer_question_openai(question: str, verbose: bool = False) -> str:\n",
        "    if verbose:\n",
        "        print(f\"\\n[answer_question] Question: {question}\")\n",
        "    # Retrieval of the most relevant stored documents from the vector store:\n",
        "    context_docs = retriever.get_relevant_documents(question)\n",
        "    context = \"\\n\".join(doc.page_content for doc in context_docs)\n",
        "    if verbose:\n",
        "        print(\"\\n[answer_question] Context:\")\n",
        "        print(context)\n",
        "    # Filling the prompt template with the current values\n",
        "    llm_prompt_str = prompt.format(\n",
        "        question=question,\n",
        "        context=context,\n",
        "    )\n",
        "    # Invocation of the Amazon Bedrock LLM for text completion -- ultimately obtaining the answer\n",
        "    llm_body = json.dumps({\"prompt\": llm_prompt_str, \"max_tokens_to_sample\": 5000})\n",
        "\n",
        "    chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm = llm_openai,\n",
        "        retriever=retriever)\n",
        "\n",
        "    result = chain({\"question\": question, \"chat_history\": []})\n",
        "\n",
        "    return result['answer']\n"
      ],
      "metadata": {
        "id": "qkdcGsxKPPna"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implement metdata filter\n",
        "\n",
        "Metadata filter can be applied to limit the scope of queries to a specific customer"
      ],
      "metadata": {
        "id": "lZPNih6dNehD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a vector store with cassIO\n",
        "from cassio.table import MetadataVectorCassandraTable\n",
        "v_table = MetadataVectorCassandraTable(table=\"customer_opportunities_openai\", vector_dimension=1536)"
      ],
      "metadata": {
        "id": "KvcWrlVZ63m6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
        ")\n",
        "\n",
        "embedding_model_name = \"text-embedding-ada-002\"\n",
        "\n",
        "def search_with_customer_filter(question: str, verbose: bool = False) -> str:\n",
        "\n",
        "    query_vector = client.embeddings.create(\n",
        "        input=question,\n",
        "        model=embedding_model_name,\n",
        "    ).data[0].embedding\n",
        "\n",
        "    metadata = {}\n",
        "    metadata[\"customer_id\"] = 'CUS100'\n",
        "\n",
        "    # Retrieval of the most relevant stored documents from the vector store:\n",
        "    results = v_table.ann_search(\n",
        "        query_vector,\n",
        "        n=5,\n",
        "        metadata=metadata,\n",
        "    )\n",
        "\n",
        "    context_docs = [\n",
        "                      (result[\"body_blob\"], result[\"metadata\"][\"customer_id\"])\n",
        "                      for result in results\n",
        "                   ]\n",
        "\n",
        "    print(context_docs)\n",
        "\n",
        "    return context_docs"
      ],
      "metadata": {
        "id": "eOIjlNiV8Who"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test code snippet"
      ],
      "metadata": {
        "id": "dGeOzvKFpfIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#answer = search_with_customer_filter(\"What are the next steps?\")\n",
        "answer = answer_question_openai(\"What are the next steps?\")\n",
        "#answer = answer_question(\"What are the opportunities with identified wins?\", verbose=True)\n",
        "print(\"=\" * 60)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUZZytsQWqs_",
        "outputId": "8d186861-0a04-4e21-8871-896afca7b80f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            " The next steps are to review partner information updates and update opportunity details on August 16th, and to contact Federico Gandolfo on July 5th to discuss deal support.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio ChatBot UI"
      ],
      "metadata": {
        "id": "_fSfM-nKDR8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict(message, history):\n",
        "    response = answer_question_openai(message)\n",
        "    return response\n",
        "\n",
        "gr.ChatInterface(predict).launch()"
      ],
      "metadata": {
        "id": "UBO91-KqQUAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LangServ deployment\n",
        "\n",
        "Due to RuntimeError: asyncio.run() cannot be called from a running event loop  , the following portion need to be run from localhost.\n",
        "\n",
        "Follow these instructions to run it locally. [LangServe setup](https://github.com/langchain-ai/langserve-launch-example)"
      ],
      "metadata": {
        "id": "lWf-nDxvriMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#chain.py"
      ],
      "metadata": {
        "id": "H91hX1JNM7Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "model_id = \"gpt-4\"\n",
        "\n",
        "req_accept = \"application/json\"\n",
        "req_content_type = \"application/json\"\n",
        "\n",
        "# This, created from the vector store, will fetch the top relevant documents given a text query\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "question = \"What are the next steps?\"\n",
        "\n",
        "# Retrieval of the most relevant stored documents from the vector store:\n",
        "context_docs = retriever.get_relevant_documents(question)\n",
        "context = \"\\n\".join(doc.page_content for doc in context_docs)\n",
        "\n",
        "# Filling the prompt template with the current values\n",
        "llm_prompt_str = prompt.format(\n",
        "    question=question,\n",
        "    context=context,\n",
        ")\n",
        "# Invocation of the Amazon Bedrock LLM for text completion -- ultimately obtaining the answer\n",
        "llm_body = json.dumps({\"prompt\": llm_prompt_str, \"max_tokens_to_sample\": 5000})\n",
        "\n",
        "chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm = llm_openai,\n",
        "    retriever=retriever)\n"
      ],
      "metadata": {
        "id": "c-edYzIUrh3L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#server.py"
      ],
      "metadata": {
        "id": "dCw_8z_DM_cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langserve fastapi sse_starlette"
      ],
      "metadata": {
        "id": "TSwF4oeuuXwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "\"\"\"A server for the chain above.\"\"\"\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from langserve import add_routes\n",
        "\n",
        "\n",
        "app = FastAPI(title=\"Retrieval App\")\n",
        "\n",
        "add_routes(app, chain)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "\n",
        "    uvicorn.run(app, host=\"localhost\", port=8000)"
      ],
      "metadata": {
        "id": "nUnEO5t0uRSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
